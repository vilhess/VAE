import streamlit as st
from PIL import Image
import numpy as np
import torch
from torchvision.utils import save_image
from function_vae.coord_to_img import convert_to_img_without_show_mnist, convert_to_img_without_show_frey_face
from function_vae.generation import generate_mnist
from streamlit_drawable_canvas import st_canvas
from function_vae.recognizer import recognition_digit
import torchvision.transforms as transforms
import torch.nn as nn
from models import *


def page3():
    model = torch.load("function_vae/save_weights/weights_ff")
    model.eval()

    st.markdown(f"<h1 style='text-align: center;'>Variational Autoencoder on FREY FACE Dataset </h1>",
                unsafe_allow_html=True)
    st.subheader(" ")

    st.markdown(f"<h3 style='text-align: center;'>In this section, instead of using our VAE on digits, we will apply it to faces of the same man with different facial expressions. The VAE will approximate the distribution of each expression and generate new ones for this man.</h3>",
                unsafe_allow_html=True)
    st.subheader(" ")

    col1, col2, col3 = st.columns(3)
    with col1:
        img = Image.open("function_vae/images/some_ff_images/ex0.png")
        st.image(img, use_column_width=True)
        img = Image.open("function_vae/images/some_ff_images/ex3.png")
        st.image(img, use_column_width=True)
        img = Image.open("function_vae/images/some_ff_images/ex6.png")
        st.image(img, use_column_width=True)
    with col2:
        img = Image.open("function_vae/images/some_ff_images/ex1.png")
        st.image(img, use_column_width=True)
        img = Image.open("function_vae/images/some_ff_images/ex4.png")
        st.image(img, use_column_width=True)
        img = Image.open("function_vae/images/some_ff_images/ex7.png")
        st.image(img, use_column_width=True)
    with col3:
        img = Image.open("function_vae/images/some_ff_images/ex3.png")
        st.image(img, use_column_width=True)
        img = Image.open("function_vae/images/some_ff_images/ex5.png")
        st.image(img, use_column_width=True)
        img = Image.open("function_vae/images/some_ff_images/ex9.png")
        st.image(img, use_column_width=True)

    st.subheader("")

    st.markdown(f"<h3 style='text-align: center;'>For the digits, we utilized a 2D latent space. However, in this case, we are using a 6D latent space.</h3>",
                unsafe_allow_html=True)

    colss, colsss = st.columns(2)
    with colss:
        st.subheader(" ")
        st.subheader(" ")
        st.subheader(" ")
        st.subheader(" ")
        coord1 = st.slider("x1", float(-7), float(7), float(0), step=0.1)
        coord2 = st.slider("x2", float(-7), float(7), float(0), step=0.1)
        coord3 = st.slider("x3", float(-7), float(7), float(0), step=0.1)
        coord4 = st.slider(
            "x4",
            float(-7),
            float(7),
            float(0),
            step=0.1,
        )

    with colsss:
        img = convert_to_img_without_show_frey_face(
            (coord1, coord2, coord3, coord4))
        save_image(img, "function_vae/images/some_ff_images/made4d.png")
        img = Image.open("function_vae/images/some_ff_images/made4d.png")
        st.header(" ")
        st.header(" ")
        st.image(img, use_column_width=True)
    st.subheader(" ")
    st.markdown(f"<h3 style='text-align: center;'>The important thing to understand is that these images are generated by our model, which has never seen them before.</h3>",
                unsafe_allow_html=True)


page3()
